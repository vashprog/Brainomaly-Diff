# Brainomaly-Diff
**Diffusion-Refined Unsupervised Brain Anomaly Detection**

> âš  This repository is a research extension of the original Brainomaly project (MIT License) and is not affiliated with the original authors.

> An extension of Brainomaly with attention-based residual diffusion refinement for improved neurologic disease detection from unannotated T1-weighted brain MR images.

---

## Overview

**Brainomaly-Diff** is a research-oriented extension of the original **Brainomaly** framework for unsupervised neurologic disease detection using unannotated T1-weighted brain MRI scans.

This work introduces an **attention-based residual diffusion refinement module** on top of the original GAN-based Brainomaly architecture to:

- Improve healthy image reconstruction fidelity  
- Reduce GAN-induced artifacts  
- Enhance anomaly separability  
- Improve ROC-AUC under inductive, transductive, and AUCp evaluation protocols  

---

## Background & Attribution

This repository **builds upon and extends** the following open-source work:

> **Brainomaly: Unsupervised Neurologic Disease Detection Utilizing Unannotated T1-weighted Brain MR Images**  
> Md Mahfuzur Rahman Siddiquee *et al.*  
> IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024  

Original Brainomaly contributions include:
- GAN-based image-to-image translation
- Healthy reconstruction from mixed unannotated datasets
- Additive anomaly map generation
- Pseudo-AUC (AUCp) based inference model selection

The original implementation is released under the **MIT License**.  
All original copyright and license notices are preserved.

---

## Diffusion Model Inspiration

The proposed refinement module is inspired by:

- **Denoising Diffusion Probabilistic Models (DDPM)**  
  Ho et al., NeurIPS 2020

- **AnoDDPM: Anomaly Detection with Diffusion Models**  
  Wolleb et al., MICCAI 2022

- **Latent Diffusion Models**  
  Rombach et al., CVPR 2022

---

## Proposed Contribution (This Work)

We introduce an **Attention-Based Residual Diffusion Refiner** that operates on coarse healthy reconstructions generated by Brainomaly.

### Key Contributions
- Diffusion-based residual correction instead of direct image synthesis  
- Attention-guided refinement preserving anatomical consistency  
- Improved anomaly score contrast  
- Robust ROC-AUC improvement across all evaluation protocols  

---

## Architecture Overview

<p align="center">
  <img src="assets/architecture.png" width="800"/>
</p>

Brainomaly-Diff follows a **two-stage anomaly detection pipeline**:

1. **Coarse Reconstruction (Brainomaly GAN)**  
   The original Brainomaly generator translates input MR images into corresponding healthy reconstructions.

2. **Diffusion-Based Refinement (Ours)**  
   The coarse reconstruction is refined using an attention-based residual diffusion UNet that suppresses artifacts and improves anatomical fidelity.

The final anomaly score is computed as the absolute difference between the input image and the refined healthy reconstruction.

---

## Dataset

### Public Brain MRI Dataset (Kaggle)

The experiments in this repository were conducted using a publicly available brain MRI dataset from **Kaggle**, titled:

ğŸ‘‰ https://www.kaggle.com/datasets/lukechugh/best-alzheimer-mri-dataset-99-accuracy/data

This dataset contains T1-weighted brain MRI scans categorized into multiple classes (e.g., Alzheimerâ€™s, Normal). In this work, all images are treated in an **unsupervised setting** for anomaly detection â€” similar to the original Brainomaly assumption â€” by organizing them into â€œhealthyâ€ and â€œdiseased/mixedâ€ subsets.

**Important:**  
- This repository does not redistribute the MRI image files themselves.  
- Users should download the dataset directly from **Kaggle** following the datasetâ€™s access and licensing terms.  
- The dataset was reorganized locally to match the directory structure expected by Brainomaly-Diff (see â€œData preparationâ€ below).

### Notes on Usage
- Although the dataset provides class labels, they are used only for evaluation; training is performed without label supervision in accordance with the Brainomaly framework.
- The dataset must be downloaded manually from Kaggle due to its original licensing and terms of service.  
- Once downloaded, images should be placed into the `data/MedicalData/` folder structure described in the Data Preparation section.  
- No subject metadata files are included or redistributed in this repository.

Note: The Kaggle dataset used in this work consists of preprocessed 2D MRI slices and does not provide subject-level longitudinal information.




## Usage

### 0. Clone the Repository

```bash
git clone https://github.com/vashprog/Brainomaly-Diff.git
cd Brainomaly-Diff
```

### 1. Environment Setup

This project was developed and tested using **Python 3.9**.

#### 1.1 Create Environment from `environment.yml`

```bash
conda env create -f environment.yml
conda activate brainomalydiff
```

#### 1.2 Manual Environment Setup (Alternative)
If you prefer not to use the provided `environment.yml`, you can manually recreate a compatible environment using the steps below.

Step 1: Create and Activate Conda Environment

```bash
conda create -n brainomalydiff python=3.9
conda activate brainomalydiff
```

Step 2: Install Core Scientific Dependencies
```bash
conda install -y \
  scikit-learn \
  scikit-image \
  scipy \
  networkx \
  pillow \
  joblib \
  imageio \
  tifffile \
  lmdb \
  -c anaconda
```

Step 3: Install PyTorch with CUDA Support
We used CUDA 12.x with PyTorch 2.8.0.
```
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0
```
If CUDA is unavailable, CPU-only execution is also supported (with slower training).

Step 4: Install Visualization & Utility Libraries
```
pip install \
  numpy \
  pandas \
  matplotlib \
  seaborn \
  tqdm \
  opencv-python \
  psutil \
  sympy
```

Step 5: Install Experiment Logging (Optional)
```
pip install neptune-client

```

### Environment Notes
- Python: 3.9
- PyTorch: 2.8.0
- CUDA: 12.x
- OS tested: Ubuntu 22.04 / WSL2
- GPU recommended: â‰¥8GB VRAM

### 2. Data preparation

The folder structure should be as follows (assuming your dataset name is MedicalData):

```python
â”œâ”€data/MedicalData # data root
â”‚ â”œâ”€train   # directory for training data
â”‚ â”‚ â”œâ”€pos   # positive class (diseased) images for unannotated mixed set
â”‚ â”‚ â”‚ â”œâ”€xxx.png
â”‚ â”‚ â”‚ â”œâ”€ ......
â”‚ â”‚ â”œâ”€neg_mixed   # negative class (healthy) images for unannotated mixed set
â”‚ â”‚ â”‚ â”œâ”€yyy.png
â”‚ â”‚ â”‚ â”œâ”€ ......
â”‚ â”‚ â”œâ”€neg   # negative class (healthy) images for known healthy set
â”‚ â”‚ â”‚ â”œâ”€zzz.png
â”‚ â”‚ â”‚ â”œâ”€ ......
â”‚ â”œâ”€test   # directory for testing data
â”‚ â”‚ â”œâ”€pos
â”‚ â”‚ â”‚ â”œâ”€aaa.png
â”‚ â”‚ â”‚ â”œâ”€ ......
â”‚ â”‚ â”œâ”€neg
â”‚ â”‚ â”‚ â”œâ”€bbb.png
â”‚ â”‚ â”‚ â”œâ”€ ......
```

If your dataset is of 2D modalities, like X-ray, then you can just put your images as png files in the corresponding folders. If your dataset is of 3D modalities like MRI, then you need to store your images slice-by-slice as png files. In such cases, please rename each slice as `xxx__000.png`, `xxx__001.png`, `xxx__002.png`, ..., where `xxx` is the ID of the patient and `000`, `001`, `002`, ... are the slice numbers. For example, if you have a 3D image from a patient named `pat_001.nii.gz` with 100 slices, then you need to store the slices as `pat_001__000.png`, `pat_001__001.png`, ..., `pat_001__099.png`.

**Note for custom data**: Please adjust the image size and cropping according to your data.

### 3. Training

- We trained the model for 150000 iterations and selected the best checkpoint at 100000 iterations based on AUCp.
- Assuming your data folder is `data/MedicalData`: `bash train.sh MedicalData`

### 4. Testing

- Inductive testing: `bash test_inductive.sh MedicalData 100000`
- Transductive testing: `bash test_transductive.sh MedicalData 100000`
- AUCp calculation: `bash test_aucp.sh MedicalData 100000`

## Reproducibility

To reproduce the results reported in the paper:

1. Download the dataset from Kaggle:
   https://www.kaggle.com/datasets/lukechugh/best-alzheimer-mri-dataset-99-accuracy/data

2. Organize the dataset into the required structure under:
   data/MedicalData/

3. Train the model:
   bash train.sh MedicalData

4. Evaluate using the selected checkpoint (e.g., 100000 iterations):
   bash test_aucp.sh MedicalData 100000



## Results Summary

Brainomaly-Diff achieves consistent performance across all evaluation protocols:

- **AUCp:** ~0.969  
- **Inductive ROC-AUC:** ~0.968  
- **Transductive ROC-AUC:** ~0.968  

The model demonstrates balanced sensitivity and specificity (~90%), indicating robust anomaly separability.


## Citation

If you use this code, please cite the original Brainomaly work and relevant diffusion models:

```bibtex
@inproceedings{siddiquee2024brainomaly,
  title={Brainomaly: Unsupervised Neurologic Disease Detection Utilizing Unannotated T1-weighted Brain MR Images},
  booktitle={WACV},
  year={2024}
}
```

## Ethical Notice

This project is intended for research purposes only and is not approved for clinical diagnosis.  
Model performance may vary across datasets, scanners, and institutions.
